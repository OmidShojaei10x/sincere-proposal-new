#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ± Ùˆ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø³ÛŒÙ†Ø³ÛŒØ±
"""

import os
import requests
import json
import time
from pathlib import Path
from urllib.parse import urlparse, parse_qs
import re

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
DOWNLOAD_FOLDER = "/Users/omid/Downloads/Omid_Shojaei/Proposal/sincere/Sincere"
URLS_FILE = "instagram_urls.json"  # ÙØ§ÛŒÙ„ Ø­Ø§ÙˆÛŒ URLÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡

def ensure_folder():
    """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯"""
    Path(DOWNLOAD_FOLDER).mkdir(parents=True, exist_ok=True)
    print(f"âœ… Ù¾ÙˆØ´Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯: {DOWNLOAD_FOLDER}")

def get_file_extension(url, default='webp'):
    """ØªØ¹ÛŒÛŒÙ† Ù¾Ø³ÙˆÙ†Ø¯ ÙØ§ÛŒÙ„ Ø§Ø² URL"""
    parsed = urlparse(url)
    path = parsed.path.lower()
    
    if '.jpg' in path or 'jpg' in path:
        return 'jpg'
    elif '.jpeg' in path or 'jpeg' in path:
        return 'jpg'
    elif '.png' in path:
        return 'png'
    elif '.mp4' in path or 'video' in path:
        return 'mp4'
    elif '.webm' in path:
        return 'webm'
    else:
        return default

def clean_filename(filename):
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§Ø² Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²"""
    # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
    filename = re.sub(r'\s+', '_', filename)
    return filename

def download_file(url, folder, filename=None, retry=3):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒÚ© ÙØ§ÛŒÙ„"""
    try:
        # ØªØ¹ÛŒÛŒÙ† Ù†Ø§Ù… ÙØ§ÛŒÙ„
        if not filename:
            parsed = urlparse(url)
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§Ø² URL
            url_filename = os.path.basename(parsed.path)
            if not url_filename or '.' not in url_filename:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² hash URL Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù†Ø§Ù…
                import hashlib
                url_hash = hashlib.md5(url.encode()).hexdigest()[:12]
                ext = get_file_extension(url)
                filename = f"sincere-media-{url_hash}.{ext}"
            else:
                filename = clean_filename(url_filename)
        
        filepath = os.path.join(folder, filename)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„
        if os.path.exists(filepath):
            print(f"â­ï¸  ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª: {filename}")
            return True
        
        # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.instagram.com/',
        }
        
        response = requests.get(url, headers=headers, stream=True, timeout=30)
        response.raise_for_status()
        
        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        file_size = os.path.getsize(filepath) / 1024  # KB
        print(f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: {filename} ({file_size:.1f} KB)")
        return True
        
    except Exception as e:
        if retry > 0:
            print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {url}: {e}. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
            time.sleep(2)
            return download_file(url, folder, filename, retry-1)
        else:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {url}: {e}")
            return False

def load_urls_from_file(filepath):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ URLÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('images', []), data.get('videos', [])
    except FileNotFoundError:
        print(f"âŒ ÙØ§ÛŒÙ„ {filepath} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        return [], []
    except json.JSONDecodeError:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ JSON!")
        return [], []

def download_from_urls_file():
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ URLÙ‡Ø§"""
    ensure_folder()
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ URLÙ‡Ø§
    images, videos = load_urls_from_file(URLS_FILE)
    
    if not images and not videos:
        print("âŒ Ù‡ÛŒÚ† URLÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        print("\nğŸ“ Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª JavaScript Ø±Ø§ Ø¯Ø± Console Ú©Ø±ÙˆÙ… Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:")
        print("   ÙØ§ÛŒÙ„: extract_urls.js")
        return
    
    print(f"\nğŸ“Š Ù¾ÛŒØ¯Ø§ Ø´Ø¯: {len(images)} ØªØµÙˆÛŒØ±ØŒ {len(videos)} ÙˆÛŒØ¯ÛŒÙˆ\n")
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ±
    if images:
        print("ğŸ“¸ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ±...")
        for i, url in enumerate(images, 1):
            print(f"[{i}/{len(images)}] ", end='')
            download_file(url, DOWNLOAD_FOLDER)
            time.sleep(0.5)  # ØªØ§Ø®ÛŒØ± Ú©ÙˆØªØ§Ù‡
    
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§
    if videos:
        print("\nğŸ¬ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§...")
        for i, url in enumerate(videos, 1):
            print(f"[{i}/{len(videos)}] ", end='')
            download_file(url, DOWNLOAD_FOLDER)
            time.sleep(1)  # ØªØ§Ø®ÛŒØ± Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§
    
    print(f"\nâœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªÙ…Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print(f"ğŸ“ Ù…Ø­Ù„ Ø°Ø®ÛŒØ±Ù‡: {DOWNLOAD_FOLDER}")

if __name__ == "__main__":
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø³ÛŒÙ†Ø³ÛŒØ±...\n")
    download_from_urls_file()

